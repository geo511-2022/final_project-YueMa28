<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Yue Ma" />


<title>What does time tell?</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
      .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Spatial Data Science Final Project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">What does time tell?</h1>
<h3 class="subtitle">Using time series data to train deep learning model
for land cover classification</h3>
<h4 class="author">Yue Ma</h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Time series data is of tremendous importance in the field of
environmental sustainability. Exploring this kind of data helps us
understand the pattern of ecosystems, which allows us to detect the
abnormal changes in time and help the relative department to make
decisions. In this study, I will use one state-of-the-art time series
classification (TSC) model, fully convectional neural network (FCN) to
classify the landcover type in Cape Floristic Region.</p>
</div>
<div id="materials-and-methods" class="section level1">
<h1>Materials and methods</h1>
<div id="proposed-data-sources" class="section level2">
<h2>Proposed data sources</h2>
<p><a
href="https://egis.environment.gov.za/sa_national_land_cover_datasets">land
cover classification dataset</a>: This dataset is released by the
Forestry, Fisheries and the Environment Department of Republic of South
Africa. The dataset demonstrates the land cover change in South Africa
from 1990 to 2020.</p>
<p><a href="https://lpdaac.usgs.gov/products/mod13q1v006/">NDVI
data</a>: The time period of the NDVI data is from 2009 to 2018.</p>
<p><a href="https://chelsa-climate.org/downloads/">CHELSA dataset</a>:
monthly precipitation data, temperature data (mean) and radiation data
of study area from 2009 to 2018.</p>
<p><a
href="https://github.com/AdamWilsonLab/emma_envdata/releases/download/processed_static/soil_Total_N_.tif">soil
data</a>: Total N in the soil of study area. In this study I assume that
the soil data of the study area does not change from 2009 to 2018.</p>
<p><a
href="https://github.com/AdamWilsonLab/emma_envdata/releases/download/processed_static/MODCF_seasonality_concentration.tif">seasonality
concentration data</a>: Cloud fraction seasonality concentration of the
study area. In this study I assume that the seasonality concentration
data of the study area does not change from 2009 to 2018.</p>
<p><a
href="https://github.com/AdamWilsonLab/emma_envdata/releases/download/processed_static/nasadem.tif">DEM
data</a>: the digital elevation model of study area.In this study I
assume that the DEM data of the study area does not change from 2009 to
2018.</p>
<p>The data used in this study is in two categories: static and dynamic.
The precipitation data, temperature data and radiation data are
considered as dynamic data while the soil data, DEM data and seasonality
concentration data are considered as static data. (Another potential
research question for this study is whether the static and dynamic data
have same importance in this classification task)</p>
</div>
<div id="methods" class="section level2">
<h2>Methods</h2>
<p>This study can be divided into four parts:</p>
<ol style="list-style-type: decimal">
<li><p>data collection and pre-processing: In this part, I collected the
aforementioned data and normalized them into the same value range
(Except the NDVI data). The normalized value range for the NDVI data is
[-1,1], while the normalized value range for the other environmental
variables is (0,1].</p></li>
<li><p>build training and testing data sets: Based on the land cover
classification data, I select pixels that do not change during the study
period and build a mask based on them. This mask is then applied to
select pixels from the NDVI and environmental variables data. Then the
label from the classification data and the data from previous step are
combined together and then splited into training and testing
datasets.</p></li>
<li><p>build and train deep learning models: The deep learning model
used in this study is proposed in <em>Time series classification from
scratch with deep neural networks: A strong baseline</em> in 2017. In
this study, I keep the original structure of the model from the paper
and train the model with our dataset.</p></li>
<li><p>discussion: Based on the results I get from the previous step,
the performance of FCN models will be analyzed.</p></li>
</ol>
</div>
</div>
<div id="before-the-code" class="section level1">
<h1>Before the code</h1>
<p>In this study I planned to use ten years as the study period, however
the large size of dataset would run into ‘Error: vector memory exhausted
(limit reached?)’ Error. So on this website, I will only use one year as
the study period. If you are interested in the original code, please
contact me (<a href="mailto:yma28@buffalo.edu"
class="email">yma28@buffalo.edu</a>).</p>
</div>
<div id="demo-using-data-from-2018-as-an-example"
class="section level1">
<h1>Demo (using data from 2018 as an example)</h1>
<p>Here I list all the packages that I used in this study.</p>
<pre class="r"><code>library(raster)</code></pre>
<pre><code>## Loading required package: sp</code></pre>
<pre><code>## Warning: multiple methods tables found for &#39;direction&#39;</code></pre>
<pre><code>## Warning: multiple methods tables found for &#39;gridDistance&#39;</code></pre>
<pre class="r"><code>library(lubridate)</code></pre>
<pre><code>## Loading required package: timechange</code></pre>
<pre><code>## 
## Attaching package: &#39;lubridate&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:raster&#39;:
## 
##     intersect, union</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     date, intersect, setdiff, union</code></pre>
<pre class="r"><code>library(sp)
library(timechange)
library(plot3D)
library(ggplot2)
library(piggyback)
library(dst)
library(reticulate)
library(countcolors)
library(tidyterra)</code></pre>
<pre><code>## 
## Attaching package: &#39;tidyterra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:raster&#39;:
## 
##     select</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre class="r"><code>library(downloader)
library(sf)</code></pre>
<pre><code>## Linking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE</code></pre>
<pre class="r"><code>library(keras)</code></pre>
<pre><code>## 
## Attaching package: &#39;keras&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dst&#39;:
## 
##     shape</code></pre>
<pre class="r"><code>library(tensorflow)</code></pre>
<pre><code>## 
## Attaching package: &#39;tensorflow&#39;
## 
## The following object is masked from &#39;package:dst&#39;:
## 
##     shape</code></pre>
<div id="creat-time-series-to-collect-data-from-github"
class="section level2">
<h2>Creat time series to collect data from github</h2>
<p>In this part we collected the time series data from Dr. Wilson’s
github.</p>
<pre class="r"><code>#year_list = c(&#39;2009&#39;,&#39;2010&#39;,&#39;2011&#39;,&#39;2012&#39;,&#39;2013&#39;,&#39;2014&#39;,&#39;2015&#39;,&#39;2016&#39;,&#39;2017&#39;,&#39;2018&#39;)

#date_list = list() 

#count &lt;- 1
#for(i in year_list){ 
#  ss &lt;- as.Date(paste(i,&#39;-01-01&#39;,sep=&#39;&#39;))
#  dates &lt;- seq(from=ss, by=32, length.out=12)
#  for(j in 1:12){
#    temp &lt;- format(dates[[j]], format = &#39;%Y_%m_%d&#39;)
#   date_list[[count]] &lt;- temp
#    count &lt;- count + 1
#  }
#} 

#date_list

date_list = list() 

ss &lt;- as.Date(paste(2018,&#39;-01-01&#39;,sep=&#39;&#39;))
dates &lt;- seq(from=ss, by=32, length.out=12)
for(j in 1:12){
  temp &lt;- format(dates[[j]], format = &#39;%Y_%m_%d&#39;)
  date_list[[j]] &lt;- temp
}

date_list</code></pre>
<pre><code>## [[1]]
## [1] &quot;2018_01_01&quot;
## 
## [[2]]
## [1] &quot;2018_02_02&quot;
## 
## [[3]]
## [1] &quot;2018_03_06&quot;
## 
## [[4]]
## [1] &quot;2018_04_07&quot;
## 
## [[5]]
## [1] &quot;2018_05_09&quot;
## 
## [[6]]
## [1] &quot;2018_06_10&quot;
## 
## [[7]]
## [1] &quot;2018_07_12&quot;
## 
## [[8]]
## [1] &quot;2018_08_13&quot;
## 
## [[9]]
## [1] &quot;2018_09_14&quot;
## 
## [[10]]
## [1] &quot;2018_10_16&quot;
## 
## [[11]]
## [1] &quot;2018_11_17&quot;
## 
## [[12]]
## [1] &quot;2018_12_19&quot;</code></pre>
</div>
<div id="download-and-clean-all-required-data" class="section level2">
<h2>Download and clean all required data</h2>
<p>Here, I load all the NDVI data and compact them as one
three-dimensional array. I firstly go through the data to check if there
is any N.A or infinity values in the array. If there are infinity
values, replace them with N.A values.</p>
</div>
</div>
<div id="download-the-data" class="section level1">
<h1>download the data</h1>
<p>In this part I will show the code for downloading the data from
Dr. Wilson’s github. I also uploaded the data in the release so this
download code is commented out. Feel free to comment it in and use it if
you want to download the data by yourself.</p>
<pre class="r"><code>#ndvi_path &lt;- &quot;the place where you save your NDVI data&quot;
#env_path &lt;- &quot;the place where you save your env data&quot;

#download the NDVI data from Dr.Wilson&#39;s github
#for(i in 1:12){
#  sample_data &lt;- pb_download(paste(date_list[[i]],&#39;.tif&#39;,sep = &#39;&#39;),
#            repo = &quot;AdamWilsonLab/emma_envdata&quot;,
#            tag = &quot;raw_ndvi_modis&quot;,
#            dest = file.path(ndvi_path)
#            )
#}

#download the env data

#dem_data &lt;- pb_download(&#39;nasadem.tif&#39;,
#            repo = &quot;AdamWilsonLab/emma_envdata&quot;,
#            tag = &quot;processed_static&quot;,
#            dest = file.path(env_path)
#            )

#soil_data &lt;- pb_download(&#39;soil_Total_N_.tif&#39;,
#            repo = &quot;AdamWilsonLab/emma_envdata&quot;,
#            tag = &quot;processed_static&quot;,
#            dest = file.path(env_path)
#            )

#conc_data &lt;- pb_download(&#39;MODCF_seasonality_concentration.tif&#39;,
#            repo = &quot;AdamWilsonLab/emma_envdata&quot;,
#            tag = &quot;processed_static&quot;,
#            dest = file.path(env_path)
#            )</code></pre>
</div>
<div id="collect-ndvi-data" class="section level1">
<h1>Collect NDVI data</h1>
<p>This part collected NDVI data from January to December 2018 and
visualize them.</p>
<pre class="r"><code>NDVI_filelist = c()

for(i in 1:12){
  NDVI_filelist[i] = paste(&#39;https://github.com/geo511-2022/final_project-YueMa28/releases/download/NDVI/&#39;,date_list[i],&#39;.tif&#39; ,sep=&quot;&quot;)
}

ndvi_rasters &lt;- terra::rast(NDVI_filelist)
names(ndvi_rasters) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)


ggplot() +
  geom_spatraster(data=ndvi_rasters) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>This part normalizes the NDVI data from original value range
([80,200]) to new value range ([-1,1]).</p>
<pre class="r"><code>ndvi_rasters_norm &lt;- (ndvi_rasters-100)/100

ggplot() +
  geom_spatraster(data=ndvi_rasters_norm) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>This part calculates the exact value range of this normalized NDVI
data.</p>
<pre class="r"><code>ndvi_arr_norm = as.array(ndvi_rasters_norm)

print(paste(&quot;There are nan values in NDVI data: &quot;,as.character(NaN %in% ndvi_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in NDVI data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in NDVI data: &quot;,as.character(Inf %in% ndvi_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in NDVI data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of NDVI data (without nan): &quot;,min(ndvi_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of NDVI data (without nan):  -0.2&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of NDVI data (without nan): &quot;,max(ndvi_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of NDVI data (without nan):  0.99&quot;</code></pre>
<p>This part visualizes the normalized NDVI data.</p>
<pre class="r"><code>image(ndvi_arr_norm[nrow(ndvi_arr_norm):1,,1],asp=1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="collect-the-environmental-data" class="section level1">
<h1>collect the environmental data</h1>
<p>The environmental data have been already downloaded and uploaded in
the release. Here is the code for loading them.</p>
<pre class="r"><code>env_filelist = c()

env_filelist[1] = &quot;https://github.com/geo511-2022/final_project-YueMa28/releases/download/ENV/nasadem.tif&quot;
env_filelist[2] = &quot;https://github.com/geo511-2022/final_project-YueMa28/releases/download/ENV/soil_Total_N_.tif&quot;
env_filelist[3] = &quot;https://github.com/geo511-2022/final_project-YueMa28/releases/download/ENV/MODCF_seasonality_concentration.tif&quot;

env_rasters &lt;- terra::rast(env_filelist)
names(env_rasters) &lt;- c(&quot;dem&quot;,&quot;soil&quot;,&quot;concentration&quot;)

ggplot() +
  geom_spatraster(data=env_rasters) +
  facet_wrap(~lyr, ncol = 3) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>This part shows the value range of environmental variables.</p>
<pre class="r"><code>env_arr_ori = as.array(env_rasters)

print(paste(&quot;There are nan values in static data: &quot;,as.character(NaN %in% env_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in static data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in static data: &quot;,as.character(Inf %in% env_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in static data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of static data (without nan): &quot;,min(env_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of static data (without nan):  -2.88884997367859&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of static data (without nan): &quot;,max(env_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of static data (without nan):  2177.22973632812&quot;</code></pre>
<p>Here we normalized the environmental data and visualize them.</p>
<pre class="r"><code>env_rasters_norm1 &lt;- terra::rast()

dem_rasters &lt;- terra::rast(env_filelist[1])
dem_min &lt;- terra::minmax(dem_rasters)[1]
dem_max &lt;- terra::minmax(dem_rasters)[2]
dem_rasters_norm &lt;- (dem_rasters - dem_min + 1) / (dem_max - dem_min + 2)


soil_rasters &lt;- terra::rast(env_filelist[2])
soil_min &lt;- terra::minmax(soil_rasters)[1]
soil_max &lt;- terra::minmax(soil_rasters)[2]
soil_rasters_norm &lt;- (soil_rasters - soil_min + 1) / (soil_max - soil_min + 2)


conc_rasters &lt;- terra::rast(env_filelist[3])
conc_min &lt;- terra::minmax(conc_rasters)[1]
conc_max &lt;- terra::minmax(conc_rasters)[2]
conc_rasters_norm &lt;- (conc_rasters - conc_min + 1) / (conc_max - conc_min + 2)

env_rasters_norm &lt;- c(dem_rasters_norm,soil_rasters_norm,conc_rasters_norm)
names(env_rasters_norm) &lt;- c(&quot;dem&quot;,&quot;soil&quot;,&quot;concentration&quot;)

ggplot() +
  geom_spatraster(data=env_rasters_norm) +
  facet_wrap(~lyr, ncol = 3) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Here we explore the detailed information about the normalized
environmental data.</p>
<pre class="r"><code>env_arr_norm = as.array(env_rasters_norm)

print(paste(&quot;There are nan values in static data: &quot;,as.character(NaN %in% env_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in static data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in static data: &quot;,as.character(Inf %in% env_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in static data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of static data (without nan): &quot;,min(env_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of static data (without nan):  0.000458270236217911&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of static data (without nan): &quot;,max(env_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of static data (without nan):  0.999541729763794&quot;</code></pre>
</div>
<div id="load-the-dynamic-data" class="section level1">
<h1>load the dynamic data</h1>
<p>The precipitation (pr), radiation (rsds) and temperature (tas) data
have been uploaded in the release part. The code below shows how to load
and visualize them.</p>
<pre class="r"><code>pr_filelist = c()
month &lt;- c(&quot;01&quot;,&quot;02&quot;,&quot;03&quot;,&quot;04&quot;,&quot;05&quot;,&quot;06&quot;,&quot;07&quot;,&quot;08&quot;,&quot;09&quot;,&quot;10&quot;,&quot;11&quot;,&quot;12&quot;)

for(i in month){
  pr_filelist[i] = paste(&#39;https://github.com/geo511-2022/final_project-YueMa28/releases/download/dynamic_pr/pr_&#39;,i,&#39;_2018.tif&#39; ,sep=&quot;&quot;)
}

pr_rasters &lt;- terra::rast(pr_filelist)
names(pr_rasters) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)
pr_rasters=terra::project(pr_rasters,ndvi_rasters_norm)

ggplot() +
  geom_spatraster(data=pr_rasters) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Here we explore the detailed information of precipitation data.</p>
<pre class="r"><code>prec_arr_ori &lt;- as.array(pr_rasters)

print(paste(&quot;There are nan values in precipitation data: &quot;,as.character(NaN %in% prec_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in precipitation data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in precipitation data: &quot;,as.character(Inf %in% prec_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in precipitation data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of precipitation data (without nan): &quot;,min(prec_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of precipitation data (without nan):  0&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of precipitation data (without nan): &quot;,max(prec_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of precipitation data (without nan):  41017.8359375&quot;</code></pre>
<p>Here we normalize the precipitation data and visualize them.</p>
<pre class="r"><code>pr_rasters_norm1 &lt;- terra::rast()

for(i in 1:11){
  current_raster &lt;- terra::rast(pr_filelist[i])
  current_min &lt;- terra::minmax(current_raster)[1]
  current_max &lt;- terra::minmax(current_raster)[2]
  current_raster_norm &lt;- (current_raster - current_min + 1) / (current_max - current_min + 2)
  current_raster_norm = terra::project(current_raster_norm,ndvi_rasters_norm)
  pr_rasters_norm1 &lt;- c(pr_rasters_norm1,current_raster_norm)
}</code></pre>
<pre><code>## Warning: [rast] the first raster was empty and was ignored</code></pre>
<pre class="r"><code>current_raster &lt;- terra::rast(pr_filelist[12])
current_min &lt;- terra::minmax(current_raster)[1]
current_max &lt;- terra::minmax(current_raster)[2]
current_raster_norm &lt;- (current_raster - current_min + 1) / (current_max - current_min + 2)
current_raster_norm = terra::project(current_raster_norm,ndvi_rasters_norm)

pr_rasters_norm &lt;- c(pr_rasters_norm1,current_raster_norm)
names(pr_rasters_norm) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)

ggplot() +
  geom_spatraster(data=pr_rasters_norm) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Here we explore more about the normalized precipitation data.</p>
<pre class="r"><code>prec_arr_norm &lt;- as.array(pr_rasters_norm)

print(paste(&quot;There are nan values in precipitation data: &quot;,as.character(NaN %in% prec_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in precipitation data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in precipitation data: &quot;,as.character(Inf %in% prec_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in precipitation data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of precipitation data (without nan): &quot;,min(prec_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of precipitation data (without nan):  2.44033381022746e-05&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of precipitation data (without nan): &quot;,max(prec_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of precipitation data (without nan):  0.999903976917267&quot;</code></pre>
<p>Here we load the rsds data and visualize them.</p>
<pre class="r"><code>rsds_filelist = c()
month &lt;- c(&quot;01&quot;,&quot;02&quot;,&quot;03&quot;,&quot;04&quot;,&quot;05&quot;,&quot;06&quot;,&quot;07&quot;,&quot;08&quot;,&quot;09&quot;,&quot;10&quot;,&quot;11&quot;,&quot;12&quot;)

for(i in month){
  rsds_filelist[i] = paste(&#39;https://github.com/geo511-2022/final_project-YueMa28/releases/download/dynamic_rsds/rsds_&#39;,i,&#39;_2018.tif&#39; ,sep=&quot;&quot;)
}

rsds_rasters &lt;- terra::rast(rsds_filelist)
names(rsds_rasters) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)
rsds_rasters = terra::project(rsds_rasters,ndvi_rasters_norm)

ggplot() +
  geom_spatraster(data=rsds_rasters) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Here we explore the details of the original rsds data.</p>
<pre class="r"><code>rsds_arr_ori &lt;- as.array(rsds_rasters)
print(paste(&quot;There are nan values in downwelling shortwave flux data: &quot;,as.character(NaN %in% rsds_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in downwelling shortwave flux data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in downwelling shortwave flux data: &quot;,as.character(Inf %in% rsds_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in downwelling shortwave flux data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of downwelling shortwave flux data (without nan): &quot;,min(rsds_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of downwelling shortwave flux data (without nan):  3.93215537071228&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of downwelling shortwave flux data (without nan): &quot;,max(rsds_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of downwelling shortwave flux data (without nan):  33.3390007019043&quot;</code></pre>
<p>Here we normalize the rsds data and visualize them.</p>
<pre class="r"><code>rsds_rasters_norm1 &lt;- terra::rast()

for(i in 1:11){
  current_raster &lt;- terra::rast(rsds_filelist[i])
  current_min &lt;- terra::minmax(current_raster)[1]
  current_max &lt;- terra::minmax(current_raster)[2]
  current_raster_norm &lt;- (current_raster - current_min + 1) / (current_max - current_min + 2)
  current_raster_norm = terra::project(current_raster_norm,ndvi_rasters_norm)
  rsds_rasters_norm1 &lt;- c(rsds_rasters_norm1,current_raster_norm)
}</code></pre>
<pre><code>## Warning: [rast] the first raster was empty and was ignored</code></pre>
<pre class="r"><code>current_raster &lt;- terra::rast(rsds_filelist[12])
current_min &lt;- terra::minmax(current_raster)[1]
current_max &lt;- terra::minmax(current_raster)[2]
current_raster_norm &lt;- (current_raster - current_min + 1) / (current_max - current_min + 2)
current_raster_norm = terra::project(current_raster_norm,ndvi_rasters_norm)
rsds_rasters_norm &lt;- c(rsds_rasters_norm1,current_raster_norm)
names(rsds_rasters_norm) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)

ggplot() +
  geom_spatraster(data=rsds_rasters_norm) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Here we explore more about normalized rsds data.</p>
<pre class="r"><code>rsds_arr_norm &lt;- as.array(rsds_rasters_norm)
print(paste(&quot;There are nan values in downwelling shortwave flux data: &quot;,as.character(NaN %in% rsds_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in downwelling shortwave flux data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in downwelling shortwave flux data: &quot;,as.character(Inf %in% rsds_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in downwelling shortwave flux data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of downwelling shortwave flux data (without nan): &quot;,min(rsds_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of downwelling shortwave flux data (without nan):  0.0785741209983826&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of downwelling shortwave flux data (without nan): &quot;,max(rsds_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of downwelling shortwave flux data (without nan):  0.924350321292877&quot;</code></pre>
<p>Here we load the tas data from release and visualize them.</p>
<pre class="r"><code>tas_filelist = c()
month &lt;- c(&quot;01&quot;,&quot;02&quot;,&quot;03&quot;,&quot;04&quot;,&quot;05&quot;,&quot;06&quot;,&quot;07&quot;,&quot;08&quot;,&quot;09&quot;,&quot;10&quot;,&quot;11&quot;,&quot;12&quot;)

for(i in month){
  tas_filelist[i] = paste(&#39;https://github.com/geo511-2022/final_project-YueMa28/releases/download/dynamic_tas/tas_&#39;,i,&#39;_2018.tif&#39; ,sep=&quot;&quot;)
}

tas_rasters &lt;- terra::rast(tas_filelist)
names(tas_rasters) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)

tas_rasters = terra::project(tas_rasters,ndvi_rasters_norm)
ggplot() +
  geom_spatraster(data=tas_rasters) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Here we explore more about the original tas data.</p>
<pre class="r"><code>tas_arr_ori &lt;- as.array(tas_rasters)
print(paste(&quot;There are nan values in mean daily airtemperature data: &quot;,as.character(NaN %in% tas_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in mean daily airtemperature data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in mean daily air temperature data: &quot;,as.character(Inf %in% tas_arr_ori,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in mean daily air temperature data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of mean daily air temperature data (without nan): &quot;,min(tas_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of mean daily air temperature data (without nan):  2735.2841796875&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of mean daily air temperature data (without nan): &quot;,max(tas_arr_ori,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of mean daily air temperature data (without nan):  3017&quot;</code></pre>
<p>Here we normalize the tas data and visualize them.</p>
<pre class="r"><code>tas_rasters_norm1 &lt;- terra::rast()

for(i in 1:11){
  current_raster &lt;- terra::rast(tas_filelist[i])
  current_min &lt;- terra::minmax(current_raster)[1]
  current_max &lt;- terra::minmax(current_raster)[2]
  current_raster_norm &lt;- (current_raster - current_min + 1) / (current_max - current_min + 2)
  current_raster_norm = terra::project(current_raster_norm,ndvi_rasters_norm)
  tas_rasters_norm1 &lt;- c(tas_rasters_norm1,current_raster_norm)
}</code></pre>
<pre><code>## Warning: [rast] the first raster was empty and was ignored</code></pre>
<pre class="r"><code>current_raster &lt;- terra::rast(tas_filelist[12])
current_min &lt;- terra::minmax(current_raster)[1]
current_max &lt;- terra::minmax(current_raster)[2]
current_raster_norm &lt;- (current_raster - current_min + 1) / (current_max - current_min + 2)
current_raster_norm = terra::project(current_raster_norm,ndvi_rasters_norm)
tas_rasters_norm &lt;- c(tas_rasters_norm1,current_raster_norm)
names(tas_rasters_norm) &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)

ggplot() +
  geom_spatraster(data=tas_rasters_norm) +
  facet_wrap(~lyr, ncol = 4) </code></pre>
<pre><code>## SpatRaster resampled to ncells = 500860</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Here we explore more about the normalized tas data.</p>
<pre class="r"><code>tas_arr_norm &lt;- as.array(tas_rasters_norm)
print(paste(&quot;There are nan values in mean daily airtemperature data: &quot;,as.character(NaN %in% tas_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in mean daily airtemperature data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in mean daily air temperature data: &quot;,as.character(Inf %in% tas_arr_norm,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in mean daily air temperature data:  FALSE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The min value of mean daily air temperature data (without nan): &quot;,min(tas_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The min value of mean daily air temperature data (without nan):  0.0130536817014217&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;The max value of mean daily air temperature data (without nan): &quot;,max(tas_arr_norm,na.rm = TRUE)))</code></pre>
<pre><code>## [1] &quot;The max value of mean daily air temperature data (without nan):  0.993902444839478&quot;</code></pre>
<p>Here we combine all the data we collected above into one
spatRaster.</p>
<pre class="r"><code>#pr_rasters_norm=terra::project(pr_rasters_norm,ndvi_rasters_norm)

all_variables_raster &lt;- c(ndvi_rasters_norm,env_rasters_norm,pr_rasters_norm,rsds_rasters_norm,tas_rasters_norm)</code></pre>
<p>This part generate the label of the training dataset. The original
data has been uploaded to the release part.</p>
<pre class="r"><code>land_cover_type &lt;- terra::rast(&quot;https://github.com/geo511-2022/final_project-YueMa28/releases/download/landcover_type/clipped_1990_2020.tif&quot;)

land_cover_type=terra::project(land_cover_type,ndvi_rasters_norm)

land_cover_arr &lt;- as.array(land_cover_type)

print(paste(&quot;There are nan values in the land cover data: &quot;,as.character(NaN %in% land_cover_arr,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are nan values in the land cover data:  TRUE&quot;</code></pre>
<pre class="r"><code>print(paste(&quot;There are infinitive values in the land cover data &quot;,as.character(Inf %in% land_cover_arr,seq=&#39;&#39;)))</code></pre>
<pre><code>## [1] &quot;There are infinitive values in the land cover data  FALSE&quot;</code></pre>
<p>Here we created a binary mask to distinguish the pixels that are
shrubland from the pixels that are not. Then we visualize the mask.</p>
<pre class="r"><code>binary_mask &lt;- array(dim=c(1634,2035))

for(i in 1:1634){
  for(j in 1:2035){
    if(is.nan(land_cover_arr[i,j,1])){
      binary_mask[i,j] = NaN
    }
    else if(land_cover_arr[i,j,1] == 105){
      binary_mask[i,j] = 1
    }
    else{
      binary_mask[i,j] = 0
    }
  }
}

image(binary_mask[nrow(binary_mask):1,],asp=1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Here we created a mask that distinguish pixels whose values are all
valid from the pixels which contains invalid data. Then we visualize the
mask.</p>
<pre class="r"><code>#all_variables_arr &lt;- array(dim=c(1634,2035,12,7))

all_variables_mask &lt;- array(dim=c(1634,2035))

count_1 &lt;- 0

for(i in 1:1634){
  for(j in 1:2035){
    for(k in 1:12){
      if(is.nan(ndvi_arr_norm[i,j,k])){
        all_variables_mask[i,j] = -1
        break
      }
      else if(is.nan(prec_arr_norm[i,j,k])){
        all_variables_mask[i,j] = -1
        break
      }
      else if(is.nan(rsds_arr_norm[i,j,k])){
        all_variables_mask[i,j] = -1
        break
      }
      else if(is.nan(tas_arr_norm[i,j,k])){
        all_variables_mask[i,j] = -1
        break
      }
      else{
        all_variables_mask[i,j] = 1
        count_1 &lt;- count_1 + 1
      }
    for(h in 1:3){
      if(is.nan(env_arr_norm[i,j,h])){
        all_variables_mask[i,j] = -1
        break
      }
      else{
        all_variables_mask[i,j] = 1
        count_1 &lt;- count_1 + 1
      }
    }
    }
  }
}

image(all_variables_mask[nrow(all_variables_mask):1,],asp=1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Here we combine the two masks we created above and select pixels to
train our model. Then we visualize the combined mask.</p>
<pre class="r"><code>combine_mask &lt;- array(dim=c(1634,2035))
total_valid_count &lt;- 0
for(m in 1:1634){
  for(n in 1:2035){
    if(is.nan(binary_mask[m,n])){
      combine_mask[m,n] = -1
    }
    else if(all_variables_mask[m,n] == -1){
      combine_mask[m,n] = -1
    }
    else{
      combine_mask[m,n] = 1
      total_valid_count &lt;- total_valid_count + 1
    }
  }
}

image(combine_mask[nrow(combine_mask):1,],asp=1)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>Here we extract the time-series data from the selected pixels and
combine them into two arrays.</p>
<pre class="r"><code>total_dataset &lt;- array(dim = c(total_valid_count,12,7))
total_label &lt;- array(dim = c(total_valid_count,1))
total_dataset_count &lt;- 0
for(m in 1:1634){
  for(n in 1:2035){
    if(combine_mask[m,n] == 1){
      for(i in 1:12){
        total_dataset[total_dataset_count,i,1] = ndvi_arr_norm[m,n,i]
        total_dataset[total_dataset_count,i,2] = prec_arr_norm[m,n,i]
        total_dataset[total_dataset_count,i,3] = rsds_arr_norm[m,n,i]
        total_dataset[total_dataset_count,i,4] = tas_arr_norm[m,n,i]
        total_dataset[total_dataset_count,i,5] = env_arr_norm[m,n,1]
        total_dataset[total_dataset_count,i,6] = env_arr_norm[m,n,2]
        total_dataset[total_dataset_count,i,7] = env_arr_norm[m,n,3]
      }
      if(binary_mask[m,n] == 105){
        total_label[total_dataset_count,1] = 1
      }
      else{
        total_label[total_dataset_count,1] = 0
      }
      total_dataset_count &lt;- total_dataset_count + 1
    }
  }
}</code></pre>
<p>Here we randomly split the dataset (75%-25%) as training dataset and
testing dataset.</p>
<pre class="r"><code>set.seed(10000)
random_number &lt;- sample(1:total_valid_count,as.integer(0.75*total_valid_count),replace=F)
train_dataset &lt;- array(dim=c(as.integer(0.75*total_valid_count),12,7))
train_label &lt;- array(dim=c(as.integer(0.75*total_valid_count),1))
test_dataset &lt;- array(dim=c(as.integer(0.25*total_valid_count),12,7))
test_label &lt;- array(dim=c(as.integer(0.25*total_valid_count),1))
train_count &lt;- 0
test_count &lt;- 0
for(i in 1:total_valid_count){
  if(i %in% random_number){
    train_dataset[train_count,,] = total_dataset[i,,]
    train_label[train_count,] = total_label[i,]
    train_count = train_count + 1
  }
  else{
    test_dataset[test_count,,] = total_dataset[i,,]
    test_label[test_count,] = total_label[i,]
    test_count = test_count + 1
  }
}

dim(train_dataset) &lt;- c(as.integer(0.75*total_valid_count),12,7,1)
train_label &lt;- to_categorical(train_label,2)</code></pre>
<pre><code>## Loaded Tensorflow version 2.10.0</code></pre>
<pre class="r"><code>dim(test_dataset) &lt;- c(as.integer(0.25*total_valid_count),12,7,1)
test_label &lt;- to_categorical(test_label,2)</code></pre>
<p>Here we build the FCN model and train it with our training dataset.
Due to the limitation of Github memory, I set the epoch to 5. Please
feel free to change the epoch and batch_size number based on the memory
of your server.</p>
<pre class="r"><code>FCN_model &lt;-keras_model_sequential()
FCN_model %&gt;%
  layer_conv_2d(filter=128,kernel_size=c(5,5),strides=1,padding = &#39;same&#39;,input_shape = c(12,7,1)) %&gt;%
  layer_batch_normalization() %&gt;%
  layer_activation(&#39;relu&#39;) %&gt;%
  layer_conv_2d(filter=256,kernel_size=c(5,5),strides=1,padding = &#39;same&#39;) %&gt;%
  layer_batch_normalization() %&gt;%
  layer_activation(&#39;relu&#39;) %&gt;%
  layer_conv_2d(filters = 128,kernel_size=c(3,3),strides=1,padding = &#39;same&#39;) %&gt;%
  layer_batch_normalization() %&gt;%
  layer_activation(&#39;relu&#39;) %&gt;%
  layer_global_average_pooling_2d() %&gt;%
  layer_dense(2,activation = &#39;softmax&#39;)

FCN_model %&gt;% compile(
  optimizer = &#39;adam&#39;,
  loss = &#39;binary_crossentropy&#39;,
  metrics = c(&#39;accuracy&#39;)
)

history = FCN_model %&gt;%
  fit(train_dataset,
      train_label,
      epoch = 5,
      batch_size = 10,
      verbose=1)</code></pre>
<p>Here we show the structure of our trained model.</p>
<pre class="r"><code>summary(FCN_model)</code></pre>
<pre><code>## Model: &quot;sequential&quot;
## ________________________________________________________________________________
##  Layer (type)                  Output Shape               Param #    Trainable  
## ================================================================================
##  conv2d_2 (Conv2D)             (None, 12, 7, 128)         3328       Y          
##  batch_normalization_2 (BatchN  (None, 12, 7, 128)        512        Y          
##  ormalization)                                                                  
##  activation_2 (Activation)     (None, 12, 7, 128)         0          Y          
##  conv2d_1 (Conv2D)             (None, 12, 7, 256)         819456     Y          
##  batch_normalization_1 (BatchN  (None, 12, 7, 256)        1024       Y          
##  ormalization)                                                                  
##  activation_1 (Activation)     (None, 12, 7, 256)         0          Y          
##  conv2d (Conv2D)               (None, 12, 7, 128)         295040     Y          
##  batch_normalization (BatchNor  (None, 12, 7, 128)        512        Y          
##  malization)                                                                    
##  activation (Activation)       (None, 12, 7, 128)         0          Y          
##  global_average_pooling2d (Glo  (None, 128)               0          Y          
##  balAveragePooling2D)                                                           
##  dense (Dense)                 (None, 2)                  258        Y          
## ================================================================================
## Total params: 1,120,130
## Trainable params: 1,119,106
## Non-trainable params: 1,024
## ________________________________________________________________________________</code></pre>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>Here we evaluate the performance of our model based on the test
dataset. Based on the loss and accuracy data calculated below, it seems
that the FCN model has achieved an ideal performance. However, this
results may be caused by the limited number of training data and the
ratio between positive and negative labels. Detialed experience should
be conducted as a follow-up research to optimaize the performance of
this model.</p>
<pre class="r"><code>FCN_model %&gt;% evaluate(test_dataset, test_label)</code></pre>
<pre><code>##     loss accuracy 
##        0        1</code></pre>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
<p>Though the model was trained with only limited datasets and limited
epochs, the results still show that it is feasible to conduct land cover
classification with FCN model. For next step, I plan to try different
datasets and test the performance. Specifically, I plan to use different
bands from hyperspectral remote sensing data to train the model instead
of the environmental variables data. Different callback functions will
be taken into consideration as well to achieve a better performance of
FCN model.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Wang Z, Yan W, Oates T. Time series classification from scratch with
deep neural networks: A strong baseline[C]//2017 International joint
conference on neural networks (IJCNN). IEEE, 2017: 1578-1585.</p>
</div>

<!-- give the footer some space -->
<br/>
<br/>

<footer id="site-footer">
  <div id="footer1">
  This website is a project for Adam Wilson's <a href="https://wilsonlab.io/GEO511"><i> Spatial Data Science (GEO511) </i></a>Course at the University at Buffalo
  </div>
  <div id="footer2">
  <a rel="license" property="http://creativecommons.org/ns#license"
  href="http://creativecommons.org/licenses/by/4.0/" ><img src="img/cc-by.svg" alt="cc-by"/></a> 
  </div>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>


</body>
</html>
